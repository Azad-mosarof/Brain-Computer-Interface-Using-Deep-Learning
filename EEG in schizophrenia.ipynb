{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b7d7539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3a333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "all_files_path = glob(\"dataverse_files/*.edf\")\n",
    "print(len(all_files_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ee65f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataverse_files/h01.edf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a77023cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n"
     ]
    }
   ],
   "source": [
    "healthy_file_path = [i for i in all_files_path if 'h' in i.split('/')[1]]\n",
    "patient_file_path = [i for i in all_files_path if 's' in i.split('/')[1]]\n",
    "print(len(healthy_file_path),len(patient_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "182da5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(file_path):\n",
    "    data = mne.io.read_raw_edf(file_path, preload=True)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(l_freq=0.5, h_freq=45)\n",
    "    epochs = mne.make_fixed_length_epochs(data, duration=5, overlap=1)\n",
    "    array = epochs.get_data()\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e14dd674",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "sample_data = readData(healthy_file_path[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b11f8ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 19, 1250)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.shape #no of epochs, channels, length of signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b91bc6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "control_epochs_array = [readData(i) for i in healthy_file_path]\n",
    "\n",
    "patient_epochs_array = [readData(i) for i in patient_file_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ef3468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(240, 19, 1250)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(control_epochs_array))\n",
    "patient_epochs_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0d7b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "control_epochs_labels = [len(i)*[0] for i in control_epochs_array]\n",
    "\n",
    "patient_epochs_labels = [len(i)*[1] for i in patient_epochs_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e1e6364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(control_epochs_labels), len(patient_epochs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "422efc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = control_epochs_array + patient_epochs_array\n",
    "label_list = control_epochs_labels + patient_epochs_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0202ae9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_list = [[i]*len(j) for i,j in enumerate(data_list)]\n",
    "# len(group_list)\n",
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cedfcf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1426, 19, 1250) (1426,) (1426,)\n"
     ]
    }
   ],
   "source": [
    "data_array = np.vstack(data_list)\n",
    "label_array = np.hstack(label_list)\n",
    "group_array = np.hstack(group_list)\n",
    "print(data_array.shape, label_array.shape, group_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea211adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def mean(x):\n",
    "    return np.mean(x, axis=-1)\n",
    "\n",
    "def std(x):\n",
    "    return np.std(x, axis=-1)\n",
    "\n",
    "def ptp(x):\n",
    "    return np.ptp(x, axis=-1)\n",
    "\n",
    "def var(x):\n",
    "    return np.var(x, axis=-1)\n",
    "\n",
    "def minim(x):\n",
    "    return np.min(x, axis=-1)\n",
    "\n",
    "def maxim(x):\n",
    "    return np.max(x, axis=-1)\n",
    "\n",
    "def argminim(x):\n",
    "    return np.argmin(x, axis=-1)\n",
    "\n",
    "def argmaxim(x):\n",
    "    return np.argmax(x, axis=-1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2, axis=-1))\n",
    "\n",
    "def abs_diff_signal(x):\n",
    "    return np.sum(np.abs(np.diff(x, axis=-1)),axis=-1)\n",
    "\n",
    "def skewness(x):\n",
    "    return stats.skew(x, axis=-1)\n",
    "\n",
    "def kurtosis(x):\n",
    "    return stats.kurtosis(x, axis=-1)\n",
    "\n",
    "def concatenate_features(x):\n",
    "    return np.concatenate((mean(x), std(x),ptp(x),var(x),minim(x),\n",
    "            maxim(x),argminim(x),argmaxim(x),rms(x),abs_diff_signal(x),\n",
    "            skewness(x),kurtosis(x)), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b76700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for d in data_array:\n",
    "    features.append(concatenate_features(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea5db432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1426, 228)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array = np.array(features)\n",
    "features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab8d261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60e0bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "gkf = GroupKFold(5)\n",
    "pipe = Pipeline([('scaler',StandardScaler()), ('clf',clf)])\n",
    "param_grid = {'clf__C':[0.1,0.5,0.7,1,3,5,7]}\n",
    "gscv = GridSearchCV(pipe, param_grid, cv=gkf, n_jobs=12)\n",
    "gscv.fit(features_array, label_array, groups=group_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e6832d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6578647151934823"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8698253",
   "metadata": {},
   "source": [
    "# Using Deep Learning ( 1 D Convolution Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "232da97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_array = np.vstack(data_list)\n",
    "epochs_labels = np.hstack(label_list)\n",
    "groups_array = np.hstack(group_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90b5defe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1426, 19, 1250), (1426,), (1426,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_array.shape, epochs_labels.shape, groups_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61d973f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1426, 1250, 19)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_array = np.moveaxis(epochs_array, 1, 2)\n",
    "epochs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f57feaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 20:14:21.610577: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 20:14:22.278582: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-06 20:14:22.278644: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-06 20:14:24.974339: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-06 20:14:24.974548: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-06 20:14:24.974575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, LeakyReLU, MaxPool1D,\\\n",
    "GlobalAveragePooling1D, Dense, Dropout, AveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de3449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    clear_session()\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(filters=5, kernel_size=3, strides=1, input_shape=(1250, 19)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPool1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(Conv1D(filters=4, kernel_size=3, strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPool1D(pool_size=2, strides=2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv1D(filters=4, kernel_size=3, strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(AveragePooling1D(pool_size=2, strides=2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv1D(filters=3, kernel_size=3, strides=1))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(AveragePooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(Conv1D(filters=3, kernel_size=3, strides=1))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile('adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a2e4ee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 20:14:41.011679: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-06 20:14:41.011724: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-06 20:14:41.011760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (azad-hplaptop15da0xxx): /proc/driver/nvidia/version does not exist\n",
      "2023-02-06 20:14:41.012288: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 5)           290       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 5)          20        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 1248, 5)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 624, 5)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 622, 4)            64        \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 622, 4)           16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 622, 4)            0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 311, 4)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 311, 4)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 309, 4)            52        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 309, 4)           16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 309, 4)            0         \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 154, 4)           0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 154, 4)            0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 152, 3)            39        \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 152, 3)            0         \n",
      "                                                                 \n",
      " average_pooling1d_1 (Averag  (None, 76, 3)            0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 74, 3)             30        \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 74, 3)             0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 3)                0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 531\n",
      "Trainable params: 505\n",
      "Non-trainable params: 26\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe46a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "gkf = GroupKFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66837125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 7s 48ms/step - loss: 0.0092 - accuracy: 0.9956 - val_loss: 0.8616 - val_accuracy: 0.8706\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 2s 40ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.8455 - val_accuracy: 0.8951\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4528 - val_accuracy: 0.7622\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 2s 30ms/step - loss: 0.0121 - accuracy: 0.9947 - val_loss: 1.2412 - val_accuracy: 0.7727\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 1.0672 - val_accuracy: 0.8881\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 2s 31ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 1.7718 - val_accuracy: 0.6818\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 2s 31ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 1.4286 - val_accuracy: 0.8357\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.0101 - accuracy: 0.9947 - val_loss: 0.7627 - val_accuracy: 0.9336\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 2s 31ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.9031 - val_accuracy: 0.9231\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 1.3513 - val_accuracy: 0.8566\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.3513 - accuracy: 0.8566\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "for train_index,val_index in gkf.split(epochs_array, epochs_labels, groups=group_array):\n",
    "    train_features, train_labels = epochs_array[train_index], epochs_labels[train_index]\n",
    "    val_features, val_labels = epochs_array[val_index], epochs_labels[val_index]\n",
    "    scaler = StandardScaler()\n",
    "    train_features = scaler.fit_transform(train_features.reshape(-1,\\\n",
    "        train_features.shape[-1])).reshape(train_features.shape)\n",
    "    val_features = scaler.transform(val_features.reshape(-1,\\\n",
    "        val_features.shape[-1])).reshape(val_features.shape)    \n",
    "    model = Model()\n",
    "    model.load_weights(\"mmodel.h5\")\n",
    "    model.fit(train_features, train_labels, epochs=10, batch_size=20, validation_data=(val_features, val_labels))\n",
    "    accuracy.append(model.evaluate(val_features, val_labels)[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0154b9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8566433787345886"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4d1b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0d164bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1140, 1250, 19)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da6b1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1140, 1250, 19) -> (1140*1250,19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fca363",
   "metadata": {},
   "source": [
    "# ChronoNet: A Deep Recurrent Nural Network for Abnormal EEG Identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18662807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.researchgate.net/publication/322886158/figure/fig3/AS:614142884974634@1523434482761/Proposed-ChronoNet-architecture-which-includes-both-multiple-filters-of-exponentially.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://www.researchgate.net/publication/322886158/figure/fig3/AS:614142884974634@1523434482761/Proposed-ChronoNet-architecture-which-includes-both-multiple-filters-of-exponentially.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b2c6e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 14, 512])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.model_selection import GroupKFold\n",
    "input = torch.randn(3,14,512)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8c69cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(22, 32, kernel_size=(2,), stride=(2,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Conv1d(in_channels=22, out_channels=32, kernel_size=2, stride=2, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d2e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, inplace):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=inplace, out_channels=32, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv1d(in_channels=inplace, out_channels=32, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=inplace, out_channels=32, kernel_size=8, stride=2, padding=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x1 = self.relu(self.conv1(x))\n",
    "        x2 = self.relu(self.conv2(x))\n",
    "        x3 = self.relu(self.conv3(x))\n",
    "        x = torch.cat([x1,x2,x3], dim=1)\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fc3444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 96, 256])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = Block(14)\n",
    "out1 = block(input)\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93450a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 96, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = Block(96)\n",
    "out2 = block(out1)\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0ca3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 96, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = Block(96)\n",
    "out3 = block(out2)\n",
    "out3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1522a596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 96])\n",
      "torch.Size([3, 64, 32]) torch.Size([1, 3, 32])\n"
     ]
    }
   ],
   "source": [
    "gru = nn.GRU(input_size=96, hidden_size=32, batch_first=True)\n",
    "gru1 = nn.GRU(input_size=96, hidden_size=32, batch_first=True)\n",
    "gru2 = nn.GRU(input_size=32, hidden_size=32, batch_first=True)\n",
    "\n",
    "x = out3.permute(0, 2, 1)\n",
    "print(x.shape)\n",
    "gru_output, hn = gru1(x)\n",
    "print(gru_output.shape, hn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ac30e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru1_output, _ = gru1(x)\n",
    "gru2_output, _ = gru2(gru1_output)\n",
    "\n",
    "gru_out = torch.cat([gru1_output, gru2_output], dim=2)\n",
    "gru_out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f174178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru3_layer = nn.GRU(input_size=64, hidden_size=32, batch_first=True)\n",
    "gru3_output, _ = gru3_layer(gru_out)\n",
    "gru3_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c77fc785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 96])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_out = torch.cat([gru1_output, gru2_output, gru3_output], dim=2)\n",
    "gru_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012cf40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 64, 32]), torch.Size([1, 3, 32]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru4 = nn.GRU(input_size=96, hidden_size=32, batch_first=True)\n",
    "gru4_out, _ = gru4(gru_out)\n",
    "gru4_out.shape, _.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3f60289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 96, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer = nn.Linear(64, 1)\n",
    "linear_out = linear_layer(gru_out.permute(0,2,1))\n",
    "linear_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0de5e05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru4 = nn.GRU(input_size=96, hidden_size=32, batch_first=True)\n",
    "gru4_out, _ = gru4(linear_out.permute(0,2,1))\n",
    "gru4_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d38edad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoNet(nn.Module):\n",
    "    def __init__(self,channel):\n",
    "        super().__init__()\n",
    "        self.block1 = Block(channel)\n",
    "        self.block2 = Block(96)\n",
    "        self.block3 = Block(96)\n",
    "        self.gru1 = nn.GRU(input_size=96, hidden_size=32, batch_first=True)\n",
    "        self.gru2 = nn.GRU(input_size=32, hidden_size=32, batch_first=True)\n",
    "        self.gru3_layer = nn.GRU(input_size=64, hidden_size=32, batch_first=True)                    \n",
    "        self.gru4 = nn.GRU(input_size=96, hidden_size=32, batch_first=True)                    \n",
    "        self.linear_layer = nn.Linear(64, 1)\n",
    "        self.flatten_layer = nn.Flatten() \n",
    "        self.fc1 = nn.Linear(32,1) \n",
    "        self.relu = nn.ReLU()\n",
    "                            \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)  \n",
    "        x = self.block2(x) \n",
    "        x = self.block3(x) \n",
    "        x = x.permute(0, 2, 1)\n",
    "        gru1_output, _ = self.gru1(x)\n",
    "        gru2_output, _ = self.gru2(gru1_output)\n",
    "        gru_out = torch.cat([gru1_output, gru2_output], dim=2)\n",
    "        gru3_output, _ = self.gru3_layer(gru_out)\n",
    "        gru_out = torch.cat([gru1_output, gru2_output, gru3_output], dim=2)\n",
    "#         print(\"gru_out\",gru_out.shape)\n",
    "        linear_out = self.relu(self.linear_layer(gru_out.permute(0,2,1)))\n",
    "        gru4_out, _ = self.gru4(linear_out.permute(0,2,1))\n",
    "        out = self.flatten_layer(gru4_out)\n",
    "        out = self.fc1(out)\n",
    "        return out                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fda5fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChronoNet(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d56cf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(input)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42375cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "TDC_PATH = \"/home/azadm/Desktop/Brain_Computer_Interface_Model/EEG in schizophrenia/EEG dataset of individuals with intellectual and developmental disorder and healthy controls while observing rest and music stimuli/Data/CleanData/CleanData_TDC/Rest\"\n",
    "IDD_PATH = \"/home/azadm/Desktop/Brain_Computer_Interface_Model/EEG in schizophrenia/EEG dataset of individuals with intellectual and developmental disorder and healthy controls while observing rest and music stimuli/Data/CleanData/CleanData_IDD/Rest\"\n",
    "!rm \"/home/azadm/Desktop/Brain_Computer_Interface_Model/EEG in schizophrenia/EEG dataset of individuals with intellectual and developmental disorder and healthy controls while observing rest and music stimuli/Data/CleanData/CleanData_IDD/Rest/NDS001_Rest_CD(1).mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93280f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65a69f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "for idd in glob(IDD_PATH+\"/*.mat\"):\n",
    "    data = scipy.io.loadmat(idd)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d12ead65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'clean_data'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5bdd9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 15360)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data['clean_data']\n",
    "data.shape       #this EEG signal have total 14 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03741aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 7 non-empty values\n",
      " bads: []\n",
      " ch_names: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13\n",
      " chs: 14 misc\n",
      " custom_ref_applied: False\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 64.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 14\n",
      " projs: []\n",
      " sfreq: 128.0 Hz\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "n_channels = 14\n",
    "sampling_freq = 128  #in Hertz\n",
    "info = mne.create_info(n_channels, sfreq=sampling_freq)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2eca061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>17 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>14 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>128.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>64.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<Info | 8 non-empty values\n",
       " bads: []\n",
       " ch_names: AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4\n",
       " chs: 14 EEG\n",
       " custom_ref_applied: False\n",
       " dig: 17 items (3 Cardinal, 14 EEG)\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 64.0 Hz\n",
       " meas_date: unspecified\n",
       " nchan: 14\n",
       " projs: []\n",
       " sfreq: 128.0 Hz\n",
       ">"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_names = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
    "ch_types = ['eeg'] * 14\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "info.set_montage('standard_1020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fafbc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "raw = mne.io.RawArray(data, info)\n",
    "raw.filter(l_freq=1, h_freq=30, fir_design='firwin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5da465c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epochs = mne.make_fixed_length_epochs(raw, duration=4, overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f74b85cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 30 events and 512 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 14, 512)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b792911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34c05e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMat2mne(data):\n",
    "    ch_names = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
    "    ch_types = ['eeg'] * 14\n",
    "    info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "    info.set_montage('standard_1020')\n",
    "    raw = mne.io.RawArray(data, info)\n",
    "    raw.filter(l_freq=1, h_freq=30, fir_design='firwin')\n",
    "    raw.set_eeg_reference()\n",
    "    epochs = mne.make_fixed_length_epochs(raw, duration=4, overlap=0)\n",
    "    return epochs.get_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aea2dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "idd_subject = []\n",
    "for idd in glob(IDD_PATH+\"/*.mat\"):\n",
    "    data = scipy.io.loadmat(idd)['clean_data']\n",
    "    data = convertMat2mne(data)\n",
    "    idd_subject.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21fd66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "tdc_subject = []\n",
    "for tdc in glob(TDC_PATH+\"/*.mat\"):\n",
    "    data = scipy.io.loadmat(tdc)['clean_data']\n",
    "    data = convertMat2mne(data)\n",
    "    tdc_subject.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b1f9c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idd_subject),len(tdc_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f2be6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 14, 512)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idd_subject[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49835a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n"
     ]
    }
   ],
   "source": [
    "control_epochs_labels = [len(i)*[0] for i in tdc_subject]\n",
    "patients_epochs_labels = [len(i)*[1] for i in idd_subject]\n",
    "print(len(control_epochs_labels), len(patients_epochs_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c10895ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14\n"
     ]
    }
   ],
   "source": [
    "data_list = tdc_subject + idd_subject\n",
    "label_list = control_epochs_labels + patients_epochs_labels\n",
    "print(len(data_list), len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42c0c137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_list = [[i]*len(j) for i,j in enumerate(data_list)]\n",
    "len(group_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "083049db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class StandardScaler3D(BaseEstimator, TransformerMixin):\n",
    "    #batch, sequence, channels\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X.reshape(-1, X.shape[2]))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.scaler.transform(X.reshape(-1, X.shape[2])).reshape(X.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1836c394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 512, 14) (420,) (420,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_array = np.concatenate(data_list)\n",
    "label_array = np.concatenate(label_list)\n",
    "group_array = np.concatenate(group_list)\n",
    "data_array = np.moveaxis(data_array, 1, 2)\n",
    "print(data_array.shape, label_array.shape, group_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acdff2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold()\n",
    "accuracy = []\n",
    "for train_index,val_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "    train_features, train_labels = data_array[train_index], label_array[train_index]\n",
    "    val_features, val_labels = data_array[val_index], label_array[val_index]\n",
    "    scaler = StandardScaler3D()\n",
    "    train_features = scaler.fit_transform(train_features)\n",
    "    val_features = scaler.transform(val_features)\n",
    "    train_features = np.moveaxis(train_features, 1, 2)\n",
    "    val_features = np.moveaxis(val_features, 1, 2)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "082357f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = torch.Tensor(train_features)\n",
    "val_features = torch.Tensor(val_features)\n",
    "train_labels = torch.Tensor(train_labels)\n",
    "val_labels = torch.Tensor(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a11592b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([330, 14, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(90, 330)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "len(val_features), len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "116dc5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchmetrics in /home/azadm/.local/lib/python3.9/site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/azadm/.local/lib/python3.9/site-packages (from torchmetrics) (1.23.5)\n",
      "Requirement already satisfied: packaging in /home/azadm/.local/lib/python3.9/site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: torch>=1.8.1 in /home/azadm/.local/lib/python3.9/site-packages (from torchmetrics) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in /home/azadm/.local/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->torchmetrics) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19cd7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule, Trainer\n",
    "import torchmetrics\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e32ed151",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super(ChronoModel, self).__init__()\n",
    "        self.model = ChronoNet(14)\n",
    "        self.lr = 1e-3\n",
    "        self.bs = 12\n",
    "        self.worker = 2\n",
    "        self.acc = torchmetrics.Accuracy(task='binary')\n",
    "        self.creterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataset = TensorDataset(train_features, train_labels)\n",
    "        loader = DataLoader(dataset, batch_size=self.bs, num_workers=self.worker, suffle=True)\n",
    "        return loader\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        signal, label = batch\n",
    "        out = self(signal.float())\n",
    "        loss = self.creterion(out.flatten(), label.float().flatten())\n",
    "        acc = self.acc(out.flatten(), label.long().flatten())\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "    \n",
    "    def trained_epoch_end(self, outputs):\n",
    "        acc = torch.stack([x['acc'] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        print('train_acc: ',acc,' train_loss: ',loss)\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        dataset = TensorDataset(val_features, val_labels)\n",
    "        loader = DataLoader(dataset, batch_size=self.bs, num_workers=self.worker, suffle=True)\n",
    "        return loader\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        signal, label = batch\n",
    "        out = self(signal.float())\n",
    "        loss = self.creterion(out.flatten(), label.float().flatten())\n",
    "        acc = self.acc(out.flatten(), label.long().flatten())\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        acc = torch.stack([x['acc'] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        print('val_acc: ',acc,' va_loss: ',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "27506314",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChronoModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80d66e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "60897d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | model     | ChronoNet         | 133 K \n",
      "1 | acc       | BinaryAccuracy    | 0     \n",
      "2 | creterion | BCEWithLogitsLoss | 0     \n",
      "------------------------------------------------\n",
      "133 K     Trainable params\n",
      "0         Non-trainable params\n",
      "133 K     Total params\n",
      "0.534     Total estimated model params size (MB)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'lib' has no attribute 'X509_V_FLAG_CB_ISSUER_CHECK'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    649\u001b[0m )\n\u001b[0;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1091\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mrestore_checkpoint_after_setup:\n\u001b[1;32m   1094\u001b[0m     log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: restoring module and callbacks from checkpoint path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1161\u001b[0m, in \u001b[0;36mTrainer._log_hyperparams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog_hyperparams(hparams_initial)\n\u001b[1;32m   1160\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog_graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[0;32m-> 1161\u001b[0m \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning_utilities/core/rank_zero.py:24\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/loggers/tensorboard.py:206\u001b[0m, in \u001b[0;36mTensorBoardLogger.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;129m@rank_zero_only\u001b[39m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     dir_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_dir\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# prepare the file path\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning_utilities/core/rank_zero.py:24\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning_fabric/loggers/tensorboard.py:271\u001b[0m, in \u001b[0;36mTensorBoardLogger.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;129m@rank_zero_only\u001b[39m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning_fabric/loggers/logger.py:117\u001b[0m, in \u001b[0;36mrank_zero_experiment.<locals>.experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@rank_zero_only\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_experiment\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m _DummyExperiment()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning_utilities/core/rank_zero.py:24\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning_fabric/loggers/logger.py:115\u001b[0m, in \u001b[0;36mrank_zero_experiment.<locals>.experiment.<locals>.get_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@rank_zero_only\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_experiment\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning_fabric/loggers/tensorboard.py:180\u001b[0m, in \u001b[0;36mTensorBoardLogger.experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TENSORBOARD_AVAILABLE:\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboardX\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter  \u001b[38;5;66;03m# type: ignore[no-redef]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m LooseVersion\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m tensorboard\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileWriter, SummaryWriter  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecord_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecordWriter\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m event_pb2\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojector_config_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProjectorConfig\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_file_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EventFileWriter\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_convert_np\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_np\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_embedding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     make_mat,\n\u001b[1;32m     18\u001b[0m     make_sprite,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     get_embedding_info,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorboard/summary/__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# If the V1 summary API is accessible, load and re-export it here.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorboard/summary/v1.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary \u001b[38;5;28;01mas\u001b[39;00m _audio_summary\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_scalar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary \u001b[38;5;28;01mas\u001b[39;00m _custom_scalar_summary\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistogram\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary \u001b[38;5;28;01mas\u001b[39;00m _histogram_summary\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary \u001b[38;5;28;01mas\u001b[39;00m _image_summary\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpr_curve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary \u001b[38;5;28;01mas\u001b[39;00m _pr_curve_summary\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorboard/plugins/histogram/summary.py:35\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistogram\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistogram\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary_v2\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Export V3 versions.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m histogram \u001b[38;5;241m=\u001b[39m summary_v2\u001b[38;5;241m.\u001b[39mhistogram\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorboard/plugins/histogram/summary_v2.py:35\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistogram\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lazy_tensor_creator\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_util\n\u001b[1;32m     38\u001b[0m DEFAULT_BUCKET_COUNT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhistogram_pb\u001b[39m(tag, data, buckets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorboard/util/tensor_util.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_pb2\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow_stub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes, compat, tensor_shape\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mExtractBitsFromFloat16\u001b[39m(x):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(x, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat16)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint16)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorboard/compat/tensorflow_stub/__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_graph_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m as_dtype  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DType  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m string  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Library of dtypes (Tensor element types).\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n\u001b[1;32m     22\u001b[0m _np_bfloat16 \u001b[38;5;241m=\u001b[39m pywrap_tensorflow\u001b[38;5;241m.\u001b[39mTF_bfloat16_type()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorboard/compat/tensorflow_stub/pywrap_tensorflow.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstruct\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m errors\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfile\n\u001b[1;32m     25\u001b[0m TFE_DEVICE_PLACEMENT_WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     26\u001b[0m TFE_DEVICE_PLACEMENT_SILENT_FOR_INT32 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorboard/compat/tensorflow_stub/io/__init__.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfile\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     S3_ENABLED \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/boto3/__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# ANY KIND, either express or implied. See the License for the specific\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# language governing permissions and limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Session\n\u001b[1;32m     19\u001b[0m __author__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmazon Web Services\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.13.14\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/boto3/session.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataNotFoundError, UnknownServiceError\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/botocore/session.py:30\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNSIGNED\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigloader\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcredentials\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigprovider\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfigValueStore\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/botocore/credentials.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m total_seconds\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat_shell_split\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnknownCredentialError\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PartialCredentialsError\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/botocore/config.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mendpoint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_TIMEOUT, MAX_POOL_CONNECTIONS\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidS3AddressingStyleError\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidRetryConfigurationError\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/botocore/endpoint.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mawsrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_request_object\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPClientError\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttpsession\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m URLLib3Session\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/botocore/awsrequest.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectionpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPConnectionPool\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectionpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPSConnectionPool\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m six\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPHeaders, HTTPResponse, urlunsplit, urlsplit, \\\n\u001b[1;32m     29\u001b[0m      urlencode, MutableMapping\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/botocore/utils.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mawsrequest\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttpsession\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m         json, quote, zip_longest, urlsplit, urlunsplit, OrderedDict,\n\u001b[1;32m     36\u001b[0m         six, urlparse, get_tzinfo_options, get_md5, MD5_AVAILABLE\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmoves\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getproxies, proxy_bypass\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/botocore/httpsession.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NewConnectionError, ProtocolError, ProxyError\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Always import the original SSLContext, even if it has been patched\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyopenssl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m orig_util_SSLContext \u001b[38;5;28;01mas\u001b[39;00m SSLContext\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mssl_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SSLContext\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/contrib/pyopenssl.py:50\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mTLS with SNI_-support for Python 2. Follow these instructions if you would\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mlike to verify TLS certificates in Python 2. Note, the default libraries do\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m.. _idna: https://github.com/kjd/idna\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mOpenSSL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSSL\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m x509\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenssl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m openssl_backend\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/OpenSSL/__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (C) AB Strakt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# See LICENSE for details.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mpyOpenSSL - A simple wrapper around the OpenSSL library\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mOpenSSL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m crypto, SSL\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mOpenSSL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     __author__,\n\u001b[1;32m     11\u001b[0m     __copyright__,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     __version__,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     21\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrypto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m ]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/OpenSSL/crypto.py:1556\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         ext\u001b[38;5;241m.\u001b[39m_extension \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mgc(extension, _lib\u001b[38;5;241m.\u001b[39mX509_EXTENSION_free)\n\u001b[1;32m   1553\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ext\n\u001b[0;32m-> 1556\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mX509StoreFlags\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;124;03m    Flags for X509 verification, used to change the behavior of\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;124;03m    :class:`X509Store`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;124;03m        https://www.openssl.org/docs/manmaster/man3/X509_VERIFY_PARAM_set_flags.html\u001b[39;00m\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1567\u001b[0m     CRL_CHECK \u001b[38;5;241m=\u001b[39m _lib\u001b[38;5;241m.\u001b[39mX509_V_FLAG_CRL_CHECK\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/OpenSSL/crypto.py:1577\u001b[0m, in \u001b[0;36mX509StoreFlags\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1575\u001b[0m NOTIFY_POLICY \u001b[38;5;241m=\u001b[39m _lib\u001b[38;5;241m.\u001b[39mX509_V_FLAG_NOTIFY_POLICY\n\u001b[1;32m   1576\u001b[0m CHECK_SS_SIGNATURE \u001b[38;5;241m=\u001b[39m _lib\u001b[38;5;241m.\u001b[39mX509_V_FLAG_CHECK_SS_SIGNATURE\n\u001b[0;32m-> 1577\u001b[0m CB_ISSUER_CHECK \u001b[38;5;241m=\u001b[39m \u001b[43m_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX509_V_FLAG_CB_ISSUER_CHECK\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'lib' has no attribute 'X509_V_FLAG_CB_ISSUER_CHECK'"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f223a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "4474aacafda534b54c0bd8af9994c58e8514c7ee96457468f6654a134abb818b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
